{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from pickle import load\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def findDistance(x1, y1, x2, y2):\n",
    "    dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "    return dist\n",
    "\n",
    "def findAngle(x1, y1, x2, y2):\n",
    "    if (x2 - x1) == 0 or y1 == 0:\n",
    "        return 0\n",
    "    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n",
    "    degree = int(180 / math.pi) * theta\n",
    "    return degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_image(image, pose):\n",
    "    if image is None:\n",
    "        print(f\"Failed to read image\")\n",
    "        return\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    keypoints = pose.process(image_rgb)\n",
    "    lm = keypoints.pose_landmarks\n",
    "\n",
    "    if lm is not None:\n",
    "        nose_x = lm.landmark[mp_pose.PoseLandmark.NOSE].x * w\n",
    "        nose_y = lm.landmark[mp_pose.PoseLandmark.NOSE].y * h\n",
    "        nose_z = lm.landmark[mp_pose.PoseLandmark.NOSE].z * h  # Calculating Z-axis position\n",
    "\n",
    "        l_shldr_x = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w\n",
    "        l_shldr_y = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h\n",
    "        l_shldr_z = lm.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z * h\n",
    "        r_shldr_x = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w\n",
    "        r_shldr_y = lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h\n",
    "        r_shldr_z=lm.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z * h\n",
    "\n",
    "        # Write posture data to CSV file\n",
    "        return np.array([nose_x, nose_y, nose_z, l_shldr_x,l_shldr_y,l_shldr_z,r_shldr_x,r_shldr_y,r_shldr_z],dtype=np.float32).reshape(1,-1)\n",
    "    else:\n",
    "        print(f\"No landmarks detected in image \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class slouch_detection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(slouch_detection,self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(9,36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36,15),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(15,12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12,6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6,3),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slouch_detector(x):\n",
    "    scaler=load(open('scaler.pkl', 'rb'))\n",
    "    x=scaler.fit_transform(x)\n",
    "    x=torch.tensor(x)\n",
    "    model=slouch_detection()\n",
    "    model.load_state_dict(torch.load(\"slouch_detector.pt\"))\n",
    "    ans=model(x)\n",
    "    print(ans.item())\n",
    "    return ans.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "blue = (255, 127, 0)\n",
    "red = (50, 50, 255)\n",
    "green = (127, 255, 0)\n",
    "dark_blue = (127, 20, 0)\n",
    "light_green = (127, 233, 100)\n",
    "yellow = (0, 255, 255)\n",
    "pink = (255, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5878906846046448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "Qt: Session management error: Could not open network socket\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6020757555961609\n",
      "0.600190281867981\n",
      "0.6021447777748108\n",
      "0.6024240851402283\n",
      "0.6014126539230347\n",
      "0.600190281867981\n",
      "0.6009686589241028\n",
      "0.5878906846046448\n",
      "0.6029049158096313\n",
      "0.6013149619102478\n",
      "0.6013031601905823\n",
      "0.6019353270530701\n",
      "0.5994634032249451\n",
      "0.601359486579895\n",
      "0.6027330160140991\n",
      "0.600443959236145\n",
      "0.5878906846046448\n",
      "0.6034913063049316\n",
      "0.601341724395752\n",
      "0.601190984249115\n",
      "0.6043651103973389\n",
      "0.5878906846046448\n",
      "0.600190281867981\n",
      "0.6007748246192932\n",
      "0.6032739281654358\n",
      "0.5994634032249451\n",
      "0.6026169657707214\n",
      "0.601190984249115\n",
      "0.6023461222648621\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'landmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m lm \u001b[38;5;241m=\u001b[39m keypoints\u001b[38;5;241m.\u001b[39mpose_landmarks\n\u001b[1;32m     30\u001b[0m lmPose \u001b[38;5;241m=\u001b[39m mp_pose\u001b[38;5;241m.\u001b[39mPoseLandmark\n\u001b[0;32m---> 31\u001b[0m l_shldr_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mlm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlandmark\u001b[49m[lmPose\u001b[38;5;241m.\u001b[39mLEFT_SHOULDER]\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m*\u001b[39m w)\n\u001b[1;32m     32\u001b[0m l_shldr_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(lm\u001b[38;5;241m.\u001b[39mlandmark[lmPose\u001b[38;5;241m.\u001b[39mLEFT_SHOULDER]\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m*\u001b[39m h)\n\u001b[1;32m     33\u001b[0m r_shldr_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(lm\u001b[38;5;241m.\u001b[39mlandmark[lmPose\u001b[38;5;241m.\u001b[39mRIGHT_SHOULDER]\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m*\u001b[39m w)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'landmark'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    # Initialize the webcam\n",
    "    cap = cv2.VideoCapture(0) # this is the magic!\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    # Check if the webcam is opened correctly\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to access the webcam.\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Check if the frame is captured correctly\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to capture frame.\")\n",
    "            break\n",
    "        \n",
    "        pose=mp_pose.Pose(min_detection_confidence=0.9,min_tracking_confidence=0.9)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        keypoints = pose.process(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        lm = keypoints.pose_landmarks\n",
    "        lmPose = mp_pose.PoseLandmark\n",
    "        l_shldr_x = int(lm.landmark[lmPose.LEFT_SHOULDER].x * w)\n",
    "        l_shldr_y = int(lm.landmark[lmPose.LEFT_SHOULDER].y * h)\n",
    "        r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)\n",
    "        r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)\n",
    "        l_ear_x = int(lm.landmark[lmPose.LEFT_EAR].x * w)\n",
    "        l_ear_y = int(lm.landmark[lmPose.LEFT_EAR].y * h)\n",
    "        l_hip_x = int(lm.landmark[lmPose.LEFT_HIP].x * w)\n",
    "        l_hip_y = int(lm.landmark[lmPose.LEFT_HIP].y * h)\n",
    "        offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n",
    "        if offset < 100:\n",
    "            cv2.putText(frame, str(int(offset)) + ' Aligned', (w - 150, 30), font, 0.9, green, 2)\n",
    "        else:\n",
    "            cv2.putText(frame, str(int(offset)) + ' Not Aligned', (w - 150, 30), font, 0.9, red, 2)\n",
    "        neck_inclination = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n",
    "        torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n",
    "        cv2.circle(frame, (l_shldr_x, l_shldr_y), 7, pink, -1)\n",
    "        cv2.circle(frame, (l_ear_x, l_ear_y), 7, yellow, -1)\n",
    "        cv2.circle(frame, (l_shldr_x, l_shldr_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(frame, (r_shldr_x, r_shldr_y), 7, pink, -1)\n",
    "        cv2.circle(frame, (l_hip_x, l_hip_y), 7, yellow, -1)\n",
    "        cv2.circle(frame, (l_hip_x, l_hip_y - 100), 7, yellow, -1)\n",
    "        \n",
    "        \n",
    "        cv2.line(frame, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), green, 4)\n",
    "        cv2.line(frame, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), green, 4)\n",
    "        cv2.line(frame, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), green, 4)\n",
    "        cv2.line(frame, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), green, 4)\n",
    "\n",
    "\n",
    "        x = process_image(frame,pose)\n",
    "        res= slouch_detector(x)\n",
    "        # Display the captured frame\n",
    "        cv2.imshow('Webcam', frame)\n",
    "        \n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release the webcam and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_stuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
